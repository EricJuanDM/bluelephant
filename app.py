import streamlit as st
import time 

# --- IMPORTS DAS CLASSES REAIS DO CORE (Essenciais para o funcionamento) ---
from core.llm_agent import LLMAgent 
from core.vector_store import VectorStoreManager 

# ---------------------- CONFIGURA√á√ÉO E INICIALIZA√á√ÉO ----------------------

st.set_page_config(page_title="Agente de IA com Feedback Inteligente", layout="wide")
st.title("ü§ñ Chatbot Inteligente com Melhoria de Prompt em Tempo Real")
st.markdown("---")

@st.cache_resource
def initialize_system():
    # 1. Inicializa o Vector Store Manager (ChromaDB)
    try:
        vs_manager = VectorStoreManager()
        vs_manager.initialize_static_data() 
    except Exception as e:
        st.error(f"Erro ao inicializar Vector Store (ChromaDB). Verifique o volume Docker: {e}")
        return None
    
    # 2. Inicializa o Agente e passa o Vector Store Manager
    try:
        agent = LLMAgent(vector_store_manager=vs_manager)
    except Exception as e:
        st.error(f"Erro ao inicializar LLM Agent. Chave Gemini API configurada? Erro: {e}")
        return None
        
    return agent

agent = initialize_system()

if agent is None:
    st.warning("O sistema de IA n√£o p√¥de ser iniciado. Por favor, corrija os erros acima e reinicie.")
    st.stop()


# ---------------------- GEST√ÉO DO ESTADO DA SESS√ÉO ----------------------

if "messages" not in st.session_state:
    st.session_state.messages = []

if "feedback_history" not in st.session_state:
    st.session_state.feedback_history = []

# ---------------------- DEFINI√á√ÉO DAS ABAS ----------------------

tab_chat, tab_feedback = st.tabs(["üí¨ Chat do Agente", "üìù Feedback e Melhoria"])

# ==============================================================================
# --- √ÅREA 1: CHAT DO AGENTE ---
# ==============================================================================
with tab_chat:
    st.header("Converse com o Agente")
    
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    prompt = st.chat_input("Pergunte algo ou solicite uma a√ß√£o.")

    if prompt:
        st.session_state.messages.append({"role": "user", "content": prompt})
        
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.spinner(" O agente est√° processando a resposta e buscando informa√ß√µes..."):
            try:
                # O ERRO OCORRIA AQUI! Se o LLMAgent n√£o tivesse o m√©todo process_query.
                agent_response = agent.process_query(prompt)

                st.session_state.last_interaction = {
                    "query": prompt,
                    "response": agent_response
                }

            except Exception as e:
                # Captura qualquer falha no processamento do LLM ou Tools
                agent_response = f"Erro no Agente: Falha ao processar a pergunta. Detalhes: {e}"
                st.error(agent_response)
                
        with st.chat_message("assistant"):
            st.markdown(agent_response)
            st.session_state.messages.append({"role": "assistant", "content": agent_response})
            
            st.session_state.feedback_history.append({
                "id": len(st.session_state.feedback_history) + 1,
                "query": prompt,
                "response": agent_response
            })


# ==============================================================================
# --- √ÅREA 2: FEEDBACK E MELHORIA (Refatorada para UX) ---
# ==============================================================================
with tab_feedback:
    st.header("Avalie e Sugira Melhorias para o Agente")
    
    st.subheader("1. Fornecer Feedback sobre a Intera√ß√£o")

    feedback_options = {
        f"#{item['id']} - {item['query'][:50]}..." : item 
        for item in st.session_state.feedback_history
    }
    
    if not feedback_options:
        st.warning("Interaja no chat primeiro para ter respostas dispon√≠veis para feedback.")
        selected_key = None
        selected_interaction = None
    else:
        # Seletor para escolher qual intera√ß√£o avaliar
        selected_key = st.selectbox(
            "Selecione a Intera√ß√£o para Avaliar:",
            options=list(feedback_options.keys()),
            index=0
        )
        selected_interaction = feedback_options[selected_key]
        
        # Exibe a intera√ß√£o selecionada
        st.info(f"Pergunta: **{selected_interaction['query']}**")
        st.info(f"Resposta do Agente: **{selected_interaction['response'][:200]}...**")
    
    
    # Restante dos campos (Qualidade e Sugest√£o)
    feedback_quality = st.radio(
        "Qualidade da Resposta:",
        ('Excelente (5/5)', 'Boa (4/5)', 'Razo√°vel (3/5)', 'Ruim (2/5)', 'Incorreta (1/5)'),
        index=None,
        horizontal=True
    )
    
    feedback_suggestion = st.text_area(
        "Sugest√µes de Melhoria (Obrigat√≥rio):",
        placeholder="A resposta estava incompleta, o agente deveria ter usado a ViaCEP para a resposta.",
        height=100
    )

    def handle_feedback(interaction_key, interaction_data):
        """Fun√ß√£o chamada ao clicar no bot√£o de feedback."""
        if interaction_data and feedback_quality and feedback_suggestion:
            with st.spinner("üß† Processando feedback e gerando novo prompt..."):
                try:
                    success, message = agent.update_prompt_from_feedback(
                        query=interaction_data['query'],
                        response=interaction_data['response'],
                        rating=feedback_quality,
                        suggestion=feedback_suggestion
                    )
                except Exception as e:
                    st.error(f"‚ùå Falha no LLM Otimizador: {e}")
                    return
            
            if success:
                st.success(f"‚úÖ Sucesso! {message}")
                
                # üö® Remove a intera√ß√£o do hist√≥rico AP√ìS o sucesso para que ela n√£o seja avaliada novamente
                id_to_remove = interaction_data['id']
                st.session_state.feedback_history = [
                    item for item in st.session_state.feedback_history if item['id'] != id_to_remove
                ]
            else:
                st.info(f"‚ÑπÔ∏è Tentativa conclu√≠da. {message}")
        else:
            st.error("Por favor, selecione a qualidade e insira uma sugest√£o de melhoria.")

    # Bot√£o de Feedback
    st.button(
        "Enviar Feedback e Atualizar Prompt", 
        on_click=handle_feedback, 
        args=(selected_key, selected_interaction),
        type="primary", 
        disabled=(selected_interaction is None)
    )

    st.markdown("---")

    st.subheader("2. Status e Hist√≥rico de Prompts")
    
    st.text(f"Vers√£o Atual: {len(agent.prompt_history)}")
    st.code(agent.current_prompt, language="markdown")
    
    with st.expander(f"Hist√≥rico de {len(agent.prompt_history)} Vers√µes de Prompt"):
        for entry in reversed(agent.prompt_history):
            st.markdown(f"**Vers√£o {entry['version']}** - *Fonte: {entry['source']}*")
            st.code(entry['prompt'], language="markdown")
            if 'based_on_feedback' in entry:
                st.caption(f"Motiva√ß√£o: '{entry['based_on_feedback']['suggestion']}'")
            st.divider()